{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f30a6362-caea-4916-b796-0fbab99b41b1",
      "metadata": {
        "id": "f30a6362-caea-4916-b796-0fbab99b41b1"
      },
      "source": [
        "## Retrieve and Rerank"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f6f8d1-173d-492a-bf80-851f11071315",
      "metadata": {
        "id": "37f6f8d1-173d-492a-bf80-851f11071315"
      },
      "source": [
        "In this example we will:\n",
        "* index a BEIR dataset to Elasticsearch\n",
        "* retrieve data with BM25\n",
        "* optimize relevance with a reranking module running locally to our machine\n",
        "\n",
        "Regarding the last point, even though we are going to focus on small-size reranking modules it would be beneficial to run this notebook on a machine with access to GPUs to speed up the execution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a23ca995-c54a-4146-b7ca-e53952cb9a3a",
      "metadata": {
        "id": "a23ca995-c54a-4146-b7ca-e53952cb9a3a"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "For this notebook, you will need an **Elastic deployment**, we will be using [Elastic Cloud](https://www.elastic.co/guide/en/cloud/current/ec-getting-started.html) (if you don't have a deployment please see below to setup a free trial), **Python 3.10.x** or later and some **Python dependencies**:\n",
        "- `elasticsearch` (Elastic's Python client)\n",
        "- `sentence-transformers` (to load the reranking module locally)\n",
        "- `datasets` (Hugginface's library to download datasets with minimal effort)\n",
        "- `pytrec_eval` (Needed to compute accuracy scores such as `nDCG@10`)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80658d09-bb17-4a50-b2c1-989d2e3dd2b7",
      "metadata": {
        "id": "80658d09-bb17-4a50-b2c1-989d2e3dd2b7"
      },
      "source": [
        "## Create Elastic Cloud deployment\n",
        "\n",
        "If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?onboarding_token=vectorsearch&utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial.\n",
        "Once logged in to your Elastic Cloud account, go to the [Create deployment](https://cloud.elastic.co/deployments/create) page and select **Create deployment**. Leave all settings with their default values.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6836fec-ccd0-4fab-981c-f76f5ba7113e",
      "metadata": {
        "id": "b6836fec-ccd0-4fab-981c-f76f5ba7113e"
      },
      "source": [
        "## Installing packages\n",
        "\n",
        "Let's start by installing the necessary Python libraries (preferably in a virtual environment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b5a56591-4d9d-435b-b165-f9fbfa5615f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5a56591-4d9d-435b-b165-f9fbfa5615f6",
        "outputId": "537370cd-1e3d-4066-895c-e4f1c3845f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: elasticsearch in ./.venv/lib/python3.9/site-packages (8.15.0)\n",
            "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.9/site-packages (3.0.1)\n",
            "Requirement already satisfied: datasets in ./.venv/lib/python3.9/site-packages (2.21.0)\n",
            "Requirement already satisfied: pytrec_eval in ./.venv/lib/python3.9/site-packages (0.5)\n",
            "Requirement already satisfied: elastic-transport<9,>=8.13 in ./.venv/lib/python3.9/site-packages (from elasticsearch) (8.15.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./.venv/lib/python3.9/site-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from sentence-transformers) (2.0.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in ./.venv/lib/python3.9/site-packages (from sentence-transformers) (0.24.6)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.9/site-packages (from sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (from sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: Pillow in ./.venv/lib/python3.9/site-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in ./.venv/lib/python3.9/site-packages (from datasets) (2024.6.1)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.9/site-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in ./.venv/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.9/site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: multiprocess in ./.venv/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.9/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp in ./.venv/lib/python3.9/site-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.9/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.7.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in ./.venv/lib/python3.9/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.2.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Users/mattias/dev/git/relevancy-benchmark/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U elasticsearch sentence-transformers datasets pytrec_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfda1967-8feb-400e-b125-dc8e2c349467",
      "metadata": {
        "id": "cfda1967-8feb-400e-b125-dc8e2c349467"
      },
      "source": [
        "and let's gradually build our code structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8c5c76bc-aed0-4e44-b0a7-724470cbb7ed",
      "metadata": {
        "id": "8c5c76bc-aed0-4e44-b0a7-724470cbb7ed"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from getpass import getpass\n",
        "from typing import Any, Union\n",
        "\n",
        "from datasets.arrow_dataset import Dataset\n",
        "from datasets.dataset_dict import DatasetDict, IterableDatasetDict\n",
        "from datasets.iterable_dataset import IterableDataset\n",
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch.helpers import bulk\n",
        "from sentence_transformers import CrossEncoder\n",
        "from tqdm import tqdm\n",
        "import datasets\n",
        "import numpy as np\n",
        "import pytrec_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4128f7f-7ba2-406f-ba5d-435dd4a241f2",
      "metadata": {
        "id": "f4128f7f-7ba2-406f-ba5d-435dd4a241f2"
      },
      "source": [
        "Before we dive deeper into the code, let's set the dataset name as a constant variable in our script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "46f0a0d8-0d4c-4545-8c43-ca29a579fe62",
      "metadata": {
        "id": "46f0a0d8-0d4c-4545-8c43-ca29a579fe62"
      },
      "outputs": [],
      "source": [
        "DATASET = \"trec-covid\"\n",
        "INDEX_NAME = f\"vdb910-trec-covid\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "346a9c62-7e78-460c-938e-009eb6c45368",
      "metadata": {
        "id": "346a9c62-7e78-460c-938e-009eb6c45368"
      },
      "source": [
        "Let us also define once the necessay credentials required to access the Elastic Cloud deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "180ee614-224a-4a76-b33b-3ef38422e153",
      "metadata": {
        "id": "180ee614-224a-4a76-b33b-3ef38422e153"
      },
      "outputs": [],
      "source": [
        "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
        "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea552d3-5f15-421d-9119-6c06a386da69",
      "metadata": {
        "id": "7ea552d3-5f15-421d-9119-6c06a386da69"
      },
      "source": [
        "and initialize the Elasticseach Python client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a05f9722-ebc1-43fc-9fa4-c50ef72ea287",
      "metadata": {
        "id": "a05f9722-ebc1-43fc-9fa4-c50ef72ea287"
      },
      "outputs": [],
      "source": [
        "client = Elasticsearch(\n",
        "    hosts=\"https://ocbc-test.es.australia-southeast1.gcp.elastic-cloud.com:443\",\n",
        "    #hosts=\"https://general-purpose.es.ap-southeast-2.aws.found.io:9243\",\n",
        "    api_key=\"V3owWGZKRUI1c0JodXp4WHMyaXI6TVRhVEJqaUtURXVvSmZxdTlIODBFdw==\",\n",
        "    #api_key=\"RDJVTWVwRUJVQXNFQy12YXM5MmY6UTZVU1FMZmxSRzZwTUpxVlRyZ2VGQQ==\",\n",
        "    http_compress=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4549ab8a-6add-4a9d-a6c9-d1391de914a3",
      "metadata": {
        "id": "4549ab8a-6add-4a9d-a6c9-d1391de914a3"
      },
      "source": [
        "### Test the client\n",
        "\n",
        "Before you continue, confirm that the client has connected with this test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0336efb4-5d77-46e4-8d93-ef03b2de1b93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0336efb4-5d77-46e4-8d93-ef03b2de1b93",
        "outputId": "911cd756-498a-43b9-f68d-2cf139976acb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Successfully connected to cluster 6137dc8eb2994a41bc2a852839e3f70b (version 8.12.1)'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client_info = client.info()\n",
        "\n",
        "f\"Successfully connected to cluster {client_info['cluster_name']} (version {client_info['version']['number']})\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87eeef16-c040-4760-9be6-517fc6eefbac",
      "metadata": {
        "id": "87eeef16-c040-4760-9be6-517fc6eefbac"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de131fe-e8ec-40a2-92aa-5765235f01a9",
      "metadata": {
        "id": "4de131fe-e8ec-40a2-92aa-5765235f01a9"
      },
      "source": [
        "## Helper functions\n",
        "\n",
        "In this section we define some helper functions to increase the readability of our code.\n",
        "\n",
        "Let's start with the functions that will handle the interaction with our Elastic Cloud deployment such as:\n",
        "- creating an index\n",
        "- storing the documents\n",
        "- retrieving documents with BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "073294e4-8893-4c0a-9e80-7f34f1ea81c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "073294e4-8893-4c0a-9e80-7f34f1ea81c2",
        "outputId": "f18fea1c-7fd0-4be9-90cf-ff982fbaf4c0"
      },
      "outputs": [],
      "source": [
        "def create_index(es_client: Elasticsearch, name: str, analyzer: str = \"english\"):\n",
        "    \"\"\"\n",
        "    Creating an index into our deployment\n",
        "\n",
        "    Args:\n",
        "        `es_client`: An instance of a Python Elasticsearch client\n",
        "        `analyzer`: A string identifier of the language analyzer to be used. By default we use `english`\n",
        "            (more details at https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lang-analyzer.html)\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # we store `title` & `text` into separate fields and\n",
        "    _mappings = {\n",
        "        \"properties\": {\n",
        "            \"title\": {\"type\": \"text\", \"analyzer\": analyzer},\n",
        "            \"txt\": {\"type\": \"text\", \"analyzer\": analyzer},\n",
        "            \"emb\": {\n",
        "        \"type\": \"dense_vector\",\n",
        "        \"dims\": 768\n",
        "      }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    pipeline_body = {\n",
        "        \"processors\": [\n",
        "        {\n",
        "            \"inference\": {\n",
        "            \"model_id\": \"sentence-transformers__all-mpnet-base-v2\",\n",
        "            \"target_field\": \"inference\",\n",
        "            \"field_map\": {\n",
        "                \"txt\": \"text_field\"\n",
        "            }\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"rename\": {\n",
        "            \"field\": \"inference.predicted_value\",\n",
        "            \"target_field\": \"emb\"\n",
        "            }\n",
        "        }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Create the pipeline\n",
        "    pipeline_id = \"embeddings_pipeline\"\n",
        "    es_client.ingest.put_pipeline(id=pipeline_id, body=pipeline_body)\n",
        "\n",
        "    # create an index with the specified name\n",
        "    es_client.indices.create(\n",
        "        index=name,\n",
        "        settings={\"number_of_shards\": 1},\n",
        "        mappings=_mappings\n",
        "    )\n",
        "\n",
        "\n",
        "def index_corpus(\n",
        "    corpus: Union[DatasetDict, Dataset, IterableDatasetDict, IterableDataset],\n",
        "    index_name: str,\n",
        "    es_client: Elasticsearch,\n",
        "):\n",
        "    \"\"\"\n",
        "    Pushing documents over to our index\n",
        "\n",
        "    Args:\n",
        "        `corpus`: The corpus of the dataset we have selected. It's a Huggingface dataset with the three fields (`_id`, `title`, `text`)\n",
        "        `index_name`: The name of the Elasticsearch index\n",
        "        `es_client`: An instance of a Python Elasticsearch client\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    def get_iterable():\n",
        "        for docid, doc_title, doc_txt in tqdm(\n",
        "            zip(corpus[\"_id\"], corpus[\"title\"], corpus[\"text\"]), total=corpus.num_rows\n",
        "        ):\n",
        "            yield {\n",
        "                \"_id\": docid,\n",
        "                \"_op_type\": \"index\",\n",
        "                \"refresh\": \"wait_for\",\n",
        "                \"title\": doc_title,\n",
        "                \"txt\": doc_txt\n",
        "            }\n",
        "\n",
        "    # and bulk index them\n",
        "    bulk(client=es_client, index=index_name, actions=get_iterable(), max_retries=3, chunk_size=50, request_timeout=120)\n",
        "\n",
        "    # making sure that the index has been refreshed\n",
        "    es_client.indices.refresh(index=index_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "3f48c584-d9f9-42f6-8892-52705cddc7de",
      "metadata": {
        "id": "3f48c584-d9f9-42f6-8892-52705cddc7de"
      },
      "outputs": [],
      "source": [
        "def retrieve(\n",
        "    queries: Union[DatasetDict, Dataset, IterableDatasetDict, IterableDataset],\n",
        "    es_client: Elasticsearch,\n",
        "    index_name: str,\n",
        "    size: int = 10,\n",
        "    batch_size: int = 32,\n",
        "):\n",
        "    \"\"\"\n",
        "    Retrieve docs from the index by matching title, txt separately\n",
        "    Args:\n",
        "        `queries`: The queries of the dataset we have selected. It's a Huggingface dataset with the two fields (`_id`, `text`)\n",
        "        `es_client`: An instance of a Python Elasticsearch client\n",
        "        `index_name`: The name of the Elasticsearch index\n",
        "        `size`: The (maximum) number of documents that we will retrieve per query\n",
        "        `batch_size`: It represents the number of queries we can send per request.\n",
        "\n",
        "    Returns:\n",
        "        A nested dictionary where the outer key is the \"query id\" that points to (<doc_id>, <BM25-score>) key-value pairs e.g.\n",
        "        {\"my_query_id_1\": {\"my_doc_1\": 23.5, \"my_doc_2\": 11.33}, \"my_query_id_22\": {\"my_doc_3\": 20.5, \"my_doc_4\": 4.3}, ...}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def generate_request(query_text: str):\n",
        "        \"\"\"Create the request body for the ES requests\"\"\"\n",
        "        # return { # BM25\n",
        "        #     \"_source\": False,\n",
        "        #     \"query\": {\n",
        "        #         \"multi_match\": {\n",
        "        #             \"query\": query_text,\n",
        "        #             \"type\": \"best_fields\",\n",
        "        #             \"fields\": [\"title\", \"txt\"],\n",
        "        #             \"tie_breaker\": 0.5\n",
        "        #         }\n",
        "        #     },\n",
        "        #     \"size\": size,\n",
        "        # }\n",
        "        # return { # Vector\n",
        "        #     \"_source\": False,\n",
        "        #     \"knn\": {\n",
        "        #         \"field\": \"emb.predicted_value\",\n",
        "        #         \"k\": 10,\n",
        "        #         \"num_candidates\": 100,\n",
        "        #         \"query_vector_builder\": {\n",
        "        #             \"text_embedding\": { \n",
        "        #                 \"model_id\": \"sentence-transformers__all-mpnet-base-v2\", \n",
        "        #                 \"model_text\": query_text\n",
        "        #             }\n",
        "        #         }\n",
        "        #     }\n",
        "        # }\n",
        "        return {\n",
        "            \"_source\": False,\n",
        "            \"knn\": {\n",
        "                \"field\": \"emb\",\n",
        "                \"k\": 100,\n",
        "                \"num_candidates\": 1000,\n",
        "                \"query_vector_builder\": {\n",
        "                    \"text_embedding\": {\n",
        "                        \"model_id\": \"sentence-transformers__all-mpnet-base-v2\",\n",
        "                        \"model_text\": query_text\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            \"query\": {\n",
        "                \"multi_match\": {\n",
        "                \"query\": query_text,\n",
        "                \"type\": \"most_fields\",\n",
        "                \"fields\": [\n",
        "                    \"title\", \"txt\"\n",
        "                ],\n",
        "                \"tie_breaker\": 0.5\n",
        "                }\n",
        "            },\n",
        "            \"rank\": {\n",
        "                \"rrf\": {\n",
        "                \"window_size\": 50,\n",
        "                \"rank_constant\": 20\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def retrieve_batch(query_ids, es_requests):\n",
        "        \"\"\"Get docs for a mini-batch of requests\"\"\"\n",
        "        batch_dict = dict()\n",
        "        kwargs: dict[str, Any] = {\n",
        "            \"index\": index_name,\n",
        "            #\"search_type\": \"dfs_query_then_fetch\", # DFS not needed, one shard\n",
        "        }\n",
        "        try:\n",
        "            es_response = es_client.msearch(searches=es_requests, **kwargs)\n",
        "            for qid, resp in zip(query_ids, es_response[\"responses\"]):\n",
        "                batch_dict[qid] = {\n",
        "                    hit[\"_id\"]: hit[\"_score\"] for hit in resp[\"hits\"][\"hits\"]\n",
        "                }\n",
        "                batch = {\n",
        "                    hit[\"_id\"]: hit[\"_score\"] for hit in resp[\"hits\"][\"hits\"]\n",
        "                }\n",
        "                i = 0.1\n",
        "                for key, value in batch.items():\n",
        "                    #print(\"test\" + key + str(value))\n",
        "                    if value is None:\n",
        "                        batch[key] = 10000.0 - i\n",
        "                        i += 1 \n",
        "                batch_dict[qid] = batch\n",
        "\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "        return batch_dict\n",
        "\n",
        "    qids, requests = [], []\n",
        "    es_responses = dict()\n",
        "\n",
        "    for query in queries:\n",
        "        qids.append(query[\"_id\"])\n",
        "        requests.append({})\n",
        "        requests.append(generate_request(query[\"text\"]))\n",
        "\n",
        "        # retrieve in batches\n",
        "        if len(qids) == batch_size:\n",
        "            es_responses.update(retrieve_batch(qids, requests))\n",
        "            qids = []\n",
        "            requests = []\n",
        "\n",
        "    # check for leftovers\n",
        "    if len(qids) > 0:\n",
        "        es_responses.update(retrieve_batch(qids, requests))\n",
        "        qids, requests = [], []\n",
        "\n",
        "    return es_responses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2503a091-4300-412f-b0a8-96e762e763fb",
      "metadata": {
        "id": "2503a091-4300-412f-b0a8-96e762e763fb"
      },
      "source": [
        "Then, we move to functions that rely on Hugginface's `datasets` library to fetch the `corpus`, `queries` and `qrels` files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3d2a0d8e-d6f5-4f77-a2fb-1d554bcc3bd4",
      "metadata": {
        "id": "3d2a0d8e-d6f5-4f77-a2fb-1d554bcc3bd4"
      },
      "outputs": [],
      "source": [
        "def download_corpus(\n",
        "    dataset_name: str,\n",
        ") -> Union[DatasetDict, Dataset, IterableDatasetDict, IterableDataset]:\n",
        "    \"\"\"\n",
        "    Download corpus from Huggingface\n",
        "    Args:\n",
        "        `dataset_name`: The name of the BEIR dataset that we have selected\n",
        "    Returns:\n",
        "        An instance of a Hugggingface dataset\n",
        "    \"\"\"\n",
        "\n",
        "    mteb_dataset_name = f\"mteb/{dataset_name}\"\n",
        "\n",
        "    # Dataset({\n",
        "    #     features: ['_id', 'title', 'text'],\n",
        "    #     num_rows: 25657\n",
        "    # })\n",
        "    corpus = datasets.load_dataset(mteb_dataset_name, \"corpus\", split=\"corpus\")\n",
        "\n",
        "    return corpus\n",
        "\n",
        "\n",
        "def download_queries_and_qrels(dataset_name: str):\n",
        "    \"\"\"\n",
        "    Download queries, qrels from Huggingface\n",
        "    Args:\n",
        "        `dataset_name`: The name of the BEIR dataset that we have selected\n",
        "    Returns:\n",
        "        A tuple of: (<an instance of a Hugggingface dataset>, <a dictionary holding the qrels information>)\n",
        "    \"\"\"\n",
        "\n",
        "    mteb_dataset_name = f\"mteb/{dataset_name}\"\n",
        "    qrels_raw = datasets.load_dataset(\n",
        "        mteb_dataset_name,\n",
        "        \"default\",\n",
        "        split=\"test\" if dataset_name != \"msmarco\" else \"dev\",\n",
        "    )\n",
        "\n",
        "    # convert to `pytrec_eval` compatible format\n",
        "    qrels = defaultdict(dict)\n",
        "    for q in qrels_raw:\n",
        "        qrels[q[\"query-id\"]][q[\"corpus-id\"]] = int(q[\"score\"])\n",
        "\n",
        "    queries = datasets.load_dataset(\n",
        "        mteb_dataset_name, \"queries\", split=\"queries\"\n",
        "    ).filter(lambda r: r[\"_id\"] in qrels)\n",
        "\n",
        "    return queries, dict(qrels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0e0892-fcd3-44db-b7a3-d290782d19a5",
      "metadata": {
        "id": "dd0e0892-fcd3-44db-b7a3-d290782d19a5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "093fa778-5563-41bb-872e-f5bbc5625a29",
      "metadata": {
        "id": "093fa778-5563-41bb-872e-f5bbc5625a29"
      },
      "source": [
        "## Running the pipeline\n",
        "\n",
        "Now, we can execute the \"retrieve and rerank\" pipeline step by step\n",
        "\n",
        "### Corpus to our Elasticsearch index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0e235ee-39f0-441d-b062-5231f70ae5d7",
      "metadata": {
        "id": "b0e235ee-39f0-441d-b062-5231f70ae5d7"
      },
      "source": [
        "First, we create the index that will host the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "26586596-0be9-46ca-a881-b5c83b57f3af",
      "metadata": {
        "id": "26586596-0be9-46ca-a881-b5c83b57f3af"
      },
      "outputs": [],
      "source": [
        "create_index(name=INDEX_NAME, es_client=client)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339a8ea3-31ad-4fb6-8dba-a42588313fc3",
      "metadata": {
        "id": "339a8ea3-31ad-4fb6-8dba-a42588313fc3"
      },
      "source": [
        "Then, we download the corpus and push it into the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d0c2789f-b1f0-41b2-a06f-fd797e5d214e",
      "metadata": {
        "id": "d0c2789f-b1f0-41b2-a06f-fd797e5d214e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading readme: 100%|██████████| 1.20k/1.20k [00:00<00:00, 5.16kB/s]\n",
            "Downloading data: 100%|██████████| 200M/200M [00:18<00:00, 11.1MB/s] \n",
            "Generating corpus split: 100%|██████████| 171332/171332 [00:00<00:00, 703432.10 examples/s]\n"
          ]
        }
      ],
      "source": [
        "corpus = download_corpus(dataset_name=DATASET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "40c84175-87f0-4507-9232-07783beef65a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40c84175-87f0-4507-9232-07783beef65a",
        "outputId": "26bcb256-a9a9-40aa-b0e0-b234639a1c0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A/var/folders/j2/9mwvjw_13897hhs9j3531n9m0000gn/T/ipykernel_86286/1687613216.py:86: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
            "  bulk(client=es_client, index=index_name, actions=get_iterable(), max_retries=3, chunk_size=50, request_timeout=120)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mindex_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mes_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINDEX_NAME\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[35], line 86\u001b[0m, in \u001b[0;36mindex_corpus\u001b[0;34m(corpus, index_name, es_client)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m {\n\u001b[1;32m     78\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: docid,\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_op_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc_txt\n\u001b[1;32m     83\u001b[0m         }\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# and bulk index them\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[43mbulk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# making sure that the index has been refreshed\u001b[39;00m\n\u001b[1;32m     89\u001b[0m es_client\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mrefresh(index\u001b[38;5;241m=\u001b[39mindex_name)\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:521\u001b[0m, in \u001b[0;36mbulk\u001b[0;34m(client, actions, stats_only, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# make streaming_bulk yield successful results so we can count them\u001b[39;00m\n\u001b[1;32m    520\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myield_ok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ok, item \u001b[38;5;129;01min\u001b[39;00m streaming_bulk(\n\u001b[1;32m    522\u001b[0m     client, actions, ignore_status\u001b[38;5;241m=\u001b[39mignore_status, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    523\u001b[0m ):\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;66;03m# go through request-response pairs and detect failures\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stats_only:\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:436\u001b[0m, in \u001b[0;36mstreaming_bulk\u001b[0;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mmin\u001b[39m(max_backoff, initial_backoff \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (attempt \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, (ok, info) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    437\u001b[0m         bulk_data,\n\u001b[1;32m    438\u001b[0m         _process_bulk_chunk(\n\u001b[1;32m    439\u001b[0m             client,\n\u001b[1;32m    440\u001b[0m             bulk_actions,\n\u001b[1;32m    441\u001b[0m             bulk_data,\n\u001b[1;32m    442\u001b[0m             raise_on_exception,\n\u001b[1;32m    443\u001b[0m             raise_on_error,\n\u001b[1;32m    444\u001b[0m             ignore_status,\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    447\u001b[0m         ),\n\u001b[1;32m    448\u001b[0m     ):\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[1;32m    450\u001b[0m             action, info \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39mpopitem()\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/elasticsearch/helpers/actions.py:339\u001b[0m, in \u001b[0;36m_process_bulk_chunk\u001b[0;34m(client, bulk_actions, bulk_data, raise_on_exception, raise_on_error, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     ignore_status \u001b[38;5;241m=\u001b[39m (ignore_status,)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# send the actual request\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbulk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ApiError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    341\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _process_bulk_chunk_error(\n\u001b[1;32m    342\u001b[0m         error\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m    343\u001b[0m         bulk_data\u001b[38;5;241m=\u001b[39mbulk_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m         raise_on_error\u001b[38;5;241m=\u001b[39mraise_on_error,\n\u001b[1;32m    347\u001b[0m     )\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/elasticsearch/_sync/client/utils.py:446\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/elasticsearch/_sync/client/__init__.py:717\u001b[0m, in \u001b[0;36mElasticsearch.bulk\u001b[0;34m(self, operations, body, index, error_trace, filter_path, human, pipeline, pretty, refresh, require_alias, routing, source, source_excludes, source_includes, timeout, wait_for_active_shards)\u001b[0m\n\u001b[1;32m    712\u001b[0m __body \u001b[38;5;241m=\u001b[39m operations \u001b[38;5;28;01mif\u001b[39;00m operations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m body\n\u001b[1;32m    713\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/x-ndjson\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    716\u001b[0m }\n\u001b[0;32m--> 717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPUT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbulk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[1;32m    267\u001b[0m         method,\n\u001b[1;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[0;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/elasticsearch/_sync/client/_base.py:316\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     target \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m--> 316\u001b[0m meta, resp_body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_on_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# HEAD with a 404 is returned as a normal response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# since this is used as an 'exists' functionality.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m299\u001b[39m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m     )\n\u001b[1;32m    338\u001b[0m ):\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/elastic_transport/_transport.py:342\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta, otel_span)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     otel_span\u001b[38;5;241m.\u001b[39mset_node_metadata(node\u001b[38;5;241m.\u001b[39mhost, node\u001b[38;5;241m.\u001b[39mport, node\u001b[38;5;241m.\u001b[39mbase_url, target)\n\u001b[0;32m--> 342\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [status:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m duration:\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         )\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/elastic_transport/_node/_http_urllib3.py:167\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[0;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     body_to_send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_to_send\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRetry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m response_headers \u001b[38;5;241m=\u001b[39m HttpHeaders(response\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    176\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdata\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
            "File \u001b[0;32m~/dev/git/relevancy-benchmark/.venv/lib/python3.9/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
            "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A"
          ]
        }
      ],
      "source": [
        "index_corpus(es_client=client, corpus=corpus, index_name=INDEX_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9854e14f-5be1-437c-85cf-a65c1aa61a54",
      "metadata": {
        "id": "9854e14f-5be1-437c-85cf-a65c1aa61a54"
      },
      "source": [
        "Let's move to the retrieval part"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e91b00db-74cb-4af2-947e-8f5885e3f584",
      "metadata": {
        "id": "e91b00db-74cb-4af2-947e-8f5885e3f584"
      },
      "source": [
        "### 1st stage retrieval with BM25\n",
        "\n",
        "First, we download the `test` split of the dataset we have selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "00900be1-4c48-4dde-81b0-24000d71925a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "55a88286f9354fea87cbf4e7c86430de",
            "b4729e6ad8d54a4c9b853da46ac6eb06",
            "3d394f3f887b4ae3a27085f534d690ab",
            "2f8aa6470d854dbcbf94a96af4dfdffa",
            "0056b9b61a2b4ddbb5cc935bb6d00b7e",
            "42b58704cb744488b0e4c27792150bfb",
            "2f777fa71ccc4e74933f3949182355f5",
            "a98cad90972e407cb0b364911948afd6",
            "00a1245d83ef46ed8a301e062d8fd2a1",
            "6d4883a18a6a463da8b6b762a8c33d98",
            "67e5eb9cc9c64d1ca8d9ee3d420b5608",
            "8a8fdbe5e50a468d8d1200b60c8aada2",
            "e05d3c875d864dc5a812794ea7c5256e",
            "8c47c80da01c4261b686f7326f11b990",
            "fe7b6b97dd1b41dc9f9ac95d920b53b0",
            "06f2e2b775d24d6db28b88111489bd22",
            "bc81f4bf513f4cb2b07270f1669f53dc",
            "0b6d8b34cf764aaaad382821aa8093ef",
            "690cf81630c143f597c85a353c7ffdb7",
            "d69c7e3008094032bc2a3e89a77866f9",
            "e70f9877b9864ebaa3491b2ecf3c0185",
            "6aea695ca483431295c286f9eb9c6fa3",
            "9292bb4ff64c4435a060f9202250c26d",
            "5e09bea8ec6348a39a37cd2ccc9d393e",
            "57affd030eb84a4fbc2910328b948ba4",
            "42834e1e98f741b4873eff59b6bd6163",
            "d8b60cc1d160439a8036604a2286b927",
            "ebb8366fd7904c85a90a388ea8ddb4aa",
            "3593407a12a7481b8c6230a9e050668f",
            "2ff0a8eee73d437b9f4ca18c3aa70f97",
            "52646ef672254fed9414d2e799c66942",
            "821c1f240a6849839c816e84056eb569",
            "52a01e6aaed04e4396d62d9135a3eb2e",
            "f5a83ce3f6334d669c5f2092cf20bb53",
            "ab4ae86ce2d24e9d8bd89332bd25eb57",
            "88fc531e854b46c5882a738e44aba762",
            "12d0dbd3ac0346aa882eb5fa08dce1da",
            "c495710ac7194c599cbe4f02f025e3cd",
            "58cbc6b8ae2e432aafdbf1ba3894a67e",
            "f88bd71942934410ad7e9265967298ee",
            "0ac3cf6d2df14fdea601dd7d03953406",
            "b8dc67632ee84ca9aa6eccb50c7aadcf",
            "8af4b259809d4c4bb8152aac7053725f",
            "9f976bc08ca041d791527595cef23527",
            "2fb9821124624e0f8f6743489d668021",
            "4aba514d1e384a1a98abd9e0babb5fbb",
            "a15fd83f19b9483394151519d0e540d3",
            "69adb50083564854a5be5d8f80dfc44e",
            "f35e0db79c4c438cb8017f960715b3c5",
            "059c115f2973406f97d3376a00aea6fe",
            "5ff518c12e1a4e00a83ebfbbf2bb3269",
            "119b586f69bc4b8dbcbcbd49163283a9",
            "5757d3cd5f684f3e888b7353ff272a3c",
            "9f71b21a94a44928aa82fa4d194b50ce",
            "38bc5077a0e14303ba16a25ab7fb210e"
          ]
        },
        "id": "00900be1-4c48-4dde-81b0-24000d71925a",
        "outputId": "a985a847-8108-48fa-8254-5c05066f9b8e"
      },
      "outputs": [],
      "source": [
        "queries, qrels = download_queries_and_qrels(dataset_name=DATASET)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ca5ec96-f04e-4a99-bdb8-2f9134295795",
      "metadata": {
        "id": "8ca5ec96-f04e-4a99-bdb8-2f9134295795"
      },
      "source": [
        "* The `queries` file is a Hugginface dataset with two keys ['_id', 'text'],\n",
        "* The `qrels` file contains the relationships between a `query_id` and a list of documents. We have transformed into a `pytrec_eval`-compatible format i.e. it's a nested dictionary where the outer key is the query id that points to dictionary with (`doc_id`, `score`) key-value pairs (a score >0 denotes relevance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "830ea137-10af-4a7b-8b03-a46db89399e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "830ea137-10af-4a7b-8b03-a46db89399e5",
        "outputId": "d156200f-f22d-4aad-f3e9-04ebfca7d167"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ca8e05-853c-47fb-b0f2-9ef3f6325e0d",
      "metadata": {
        "id": "a7ca8e05-853c-47fb-b0f2-9ef3f6325e0d"
      },
      "source": [
        "Now, let's retrieve the **top-100** documents per query using BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "d950d8a3-a614-4a07-9c61-719ae5a85de4",
      "metadata": {
        "id": "d950d8a3-a614-4a07-9c61-719ae5a85de4"
      },
      "outputs": [],
      "source": [
        "bm25_responses = retrieve(\n",
        "    queries=queries, index_name=INDEX_NAME, size=100, es_client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "02c866ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'1': {'dv9m19yk': 9999.9, 'wmfcey6f': 9998.9, 'n15i01tn': 9997.9, 'kgifmjvb': 9996.9, 'vwxk5bqb': 9995.9, '5d7zien3': 9994.9, 'xljdm4zi': 9993.9, 'rsjvuumi': 9992.9, 'k9lcpjyo': 9991.9, '1915kvwk': 9990.9}, '2': {'526elsrf': 9999.9, '4068kzp0': 9998.9, 'w5kjmw88': 9997.9, '1ckrnxom': 9996.9, 'gan10za0': 9995.9, '02cy1s8x': 9994.9, '124czudi': 9993.9, '4ry9b68l': 9992.9, 'kftchnhz': 9991.9, '6exmxw6r': 9990.9}, '3': {'38mhmxvd': 9999.9, 'yzffm05r': 9998.9, '01q4pu9k': 9997.9, '2c4jk2ms': 9996.9, '88px7oq2': 9995.9, 'wfftfkam': 9994.9, '6jr3z9wx': 9993.9, 'sg55s5nv': 9992.9, 'pcyscqux': 9991.9, 'kapv6sye': 9990.9}, '4': {'9yb9a9vz': 9999.9, '6t3jrmr7': 9998.9, '7ow2dc7u': 9997.9, 'joigb8qm': 9996.9, 'f7cy5oad': 9995.9, 'qg4xl5w8': 9994.9, 'deg5hqtl': 9993.9, '2jttlljm': 9992.9, 'dumf55yg': 9991.9, 'o72xreym': 9990.9}, '5': {'5f95gve3': 9999.9, '9ujofcsm': 9998.9, 'w3ido97l': 9997.9, 'ywaefpe8': 9996.9, 'ntozf7ba': 9995.9, 'xzqksc8j': 9994.9, '9jdg7sot': 9993.9, '37oidlkd': 9992.9, 'n8jk0iv3': 9991.9, 'ifrgx8tx': 9990.9}, '6': {'x7v4y1ru': 9999.9, 'zyrzfm40': 9998.9, 'qexn0nuy': 9997.9, 'isswwnzn': 9996.9, '9jdg7sot': 9995.9, 'zf19gppx': 9994.9, 'n8jk0iv3': 9993.9, 'ulpjwpgd': 9992.9, '7qqt0hev': 9991.9, 'ile2md92': 9990.9}, '7': {'qjma4rsp': 9999.9, 'ofd2ipvs': 9998.9, '01mo6yo9': 9997.9, 'wf5cozst': 9996.9, 'm71ut1sd': 9995.9, 'g1dij8ty': 9994.9, '3g75spkc': 9993.9, 'g693adjd': 9992.9, 'fn9t38as': 9991.9, 'blrfn8qh': 9990.9}, '8': {'hnbatlj0': 9999.9, 'ckecol7i': 9998.9, 'll2pnl81': 9997.9, 'p0rqg7uk': 9996.9, 'e5q27vpw': 9995.9, 'g096k79u': 9994.9, 'upwsdgso': 9993.9, 'nghjkrow': 9992.9, 'dz1lfwzp': 9991.9, '79gozr1p': 9990.9}, '9': {'54obt430': 9999.9, '4v3d86h3': 9998.9, 'u8hogdyf': 9997.9, 'v346cpkl': 9996.9, 'wizfsv6x': 9995.9, '7bewt5q1': 9994.9, 'xm9y4ovl': 9993.9, 'z2zt4fs2': 9992.9, 'zzvmj5qy': 9991.9, 'ewnvi5j1': 9990.9}, '10': {'cb5ebiiv': 9999.9, 'all7ocnd': 9998.9, 't7p2j504': 9997.9, 'mhmno6vb': 9996.9, 'pn02p843': 9995.9, 'v941u1t1': 9994.9, 'xcxjc3po': 9993.9, 'p1jeiljo': 9992.9, 'vdrd74nz': 9991.9, 'uwix8ftr': 9990.9}, '11': {'ba5x3ysq': 9999.9, 'h1z8rg9p': 9998.9, 'gwle80we': 9997.9, 'wa6cd7yt': 9996.9, 'eazqdlds': 9995.9, '5veg78oy': 9994.9, 'tgm90lbp': 9993.9, '6opn3o7a': 9992.9, 'vc2i6auz': 9991.9, '580r9syn': 9990.9}, '12': {'hdbbgee2': 9999.9, '0ojan1ey': 9998.9, 'bdvcwaau': 9997.9, 'rb416bbs': 9996.9, 'qnpagtt1': 9995.9, 'x70u9gz6': 9994.9, 'd4qany6k': 9993.9, 'azgfda21': 9992.9, 'q1rby2to': 9991.9, 'q03884i9': 9990.9}, '13': {'2yblpbwm': 9999.9, '3cl5itxg': 9998.9, '85vnyr36': 9997.9, '7t976vq8': 9996.9, 'mfnzkvd0': 9995.9, 'sb1n3fra': 9994.9, 'wywldhr0': 9993.9, '713ey27b': 9992.9, 'lasv4e6a': 9991.9, 'bm0ldeue': 9990.9}, '14': {'p48bw6s4': 9999.9, 'na3vrf5q': 9998.9, '414grqif': 9997.9, 'j74wnaef': 9996.9, 'axns3ukm': 9995.9, '8ngri1x0': 9994.9, '37katpp3': 9993.9, 'kb8dz8hd': 9992.9, 'v0vjkwy9': 9991.9, '5906wju4': 9990.9}, '15': {'hgau3922': 9999.9, '959w9sln': 9998.9, 'zz5bpas1': 9997.9, 'zpek8i5e': 9996.9, 'rzr8qjw8': 9995.9, 'pgsdu0fu': 9994.9, 'jk73ojkp': 9993.9, 'ppxt4xg8': 9992.9, 'ej93duxi': 9991.9, 'aodv8w1i': 9990.9}, '16': {'ej93duxi': 9999.9, 'tjplc5j6': 9998.9, 'ywusapij': 9997.9, '7ftq02ev': 9996.9, 'ou7w3zkv': 9995.9, '4d4l6mzl': 9994.9, '4hbwg18z': 9993.9, 'gilpb3oy': 9992.9, 'z4vfjlbg': 9991.9, 'khpc9f98': 9990.9}, '17': {'ykfm38tg': 9999.9, 'bl4d808v': 9998.9, 'ik7ev4t0': 9997.9, 'edy3mvur': 9996.9, 'tasbdhs1': 9995.9, 'nst527yx': 9994.9, 'gey0nidn': 9993.9, 'yvxay6dn': 9992.9, 'vjg2auh7': 9991.9, 'yjx1rx3k': 9990.9}, '18': {'f9syysdw': 9999.9, 'sjenehbl': 9998.9, '7qj00qi9': 9997.9, '3ttcfhm3': 9996.9, 'r1oqwdkz': 9995.9, '471z07ac': 9994.9, 'lq7bh1sl': 9993.9, 'q0ey3wib': 9992.9, 'svtux4dk': 9991.9, 'wni08lks': 9990.9}, '19': {'y777xosr': 9999.9, 'd26y5291': 9998.9, 'i0ll585x': 9997.9, 'qud4bj12': 9996.9, 'xfwseuxu': 9995.9, 'rv2akbj8': 9994.9, 'd6v5mkj7': 9993.9, 'uhhk4t7f': 9992.9, '20ipkh78': 9991.9, 'eevs62xf': 9990.9}, '20': {'z3l6eden': 9999.9, '53107z56': 9998.9, 'nxrg9fi6': 9997.9, 'i7scw9mu': 9996.9, '7necpu7c': 9995.9, '7ae0galy': 9994.9, 'ohj6misb': 9993.9, 'v8tfxd6a': 9992.9, '240jc7l4': 9991.9, 'cvj1t0gi': 9990.9}, '21': {'0o3wjvpx': 9999.9, '98n6ycwe': 9998.9, 'afbvbgq5': 9997.9, 'kzlo48b0': 9996.9, '2apo9imk': 9995.9, 'fgwitwjm': 9994.9, '2vxnmiyj': 9993.9, 'xwpqae0r': 9992.9, 'lizwiate': 9991.9, 'inhxonsk': 9990.9}, '22': {'wkp58iov': 9999.9, 'qsy2kex1': 9998.9, 'v3qgqfwr': 9997.9, 'rmio55bx': 9996.9, 'x4093iad': 9995.9, 'xhum1ykr': 9994.9, '20zujaha': 9993.9, '1hvihwkz': 9992.9, '2k1n07on': 9991.9, 'p3fi4yej': 9990.9}, '23': {'ta9g9ceh': 9999.9, '9nbj3ckb': 9998.9, 'hzb2fkj5': 9997.9, '4ko4lwjz': 9996.9, 'u7fqjti5': 9995.9, 'lnjlyaex': 9994.9, 'komx6t5h': 9993.9, 'n4dgqo73': 9992.9, 'z28bws23': 9991.9, 'gwefujal': 9990.9}, '24': {'hycd9zua': 9999.9, 'rf6651nd': 9998.9, '3jolt83r': 9997.9, 'ff04vt1d': 9996.9, 'cctvpphp': 9995.9, 'ulmm28d5': 9994.9, '5zb96j4a': 9993.9, 'bqxyb61p': 9992.9, 'tsd6sjcx': 9991.9, 'sdpa0372': 9990.9}, '25': {'9k8r18x7': 9999.9, 't996fbad': 9998.9, 'zzljrkbf': 9997.9, '5uvv46mi': 9996.9, 'r8gyi3dn': 9995.9, 'aoi4iqkf': 9994.9, 'mdt9p6v0': 9993.9, 'pd70i3d8': 9992.9, 'h5rewhil': 9991.9, '60qmiwjm': 9990.9}, '26': {'z5u32l0w': 9999.9, '03z3wk6i': 9998.9, '1aqtqaod': 9997.9, '46njnlct': 9996.9, '0ylislv9': 9995.9, 'jt5co0n8': 9994.9, 'd3qgrjc4': 9993.9, 'bqivjudl': 9992.9, '6jiy0b55': 9991.9, 'khsvoyhp': 9990.9}, '27': {'nadzy6lm': 9999.9, '32jaz3vz': 9998.9, 'c93j35fl': 9997.9, 'ghasrwqc': 9996.9, 't0mqh9m0': 9995.9, '5j6uu16i': 9994.9, 'hv0cwf6d': 9993.9, 'xz6pq0v3': 9992.9, 'mmlqe2pl': 9991.9, '8u7d4czd': 9990.9}, '28': {'q1akwoo1': 9999.9, '7ttesiuu': 9998.9, '9eo0leey': 9997.9, 'o3ggu5qf': 9996.9, 'px2o98cv': 9995.9, 'svwkpcme': 9994.9, 'n3cg3w9v': 9993.9, 'lh5g8vl7': 9992.9, 'wnb4cltt': 9991.9, '0eizsamh': 9990.9}, '29': {'38d6gb7o': 9999.9, '2cvvkrx9': 9998.9, 'uuy94dwa': 9997.9, '4tis2he4': 9996.9, '4yuw7jo3': 9995.9, '7qd8z5e7': 9994.9, 'd6jt1dal': 9993.9, 'ovvyq18n': 9992.9, '7wjd740p': 9991.9, 'b4mdiont': 9990.9}, '30': {'1eiw7bxh': 9999.9, 'xrvynfr6': 9998.9, 'gqqdx2r5': 9997.9, '4el6qq3n': 9996.9, '4178ui2c': 9995.9, 'pkklt77i': 9994.9, 'a0drmmf7': 9993.9, 'r0znh1bi': 9992.9, 'ioqvxhar': 9991.9, '2lwzhqer': 9990.9}, '31': {'8ndl8zjz': 9999.9, '431ksdno': 9998.9, 'uer59ad3': 9997.9, '7t976vq8': 9996.9, 'q4sm3oy9': 9995.9, 'sb1n3fra': 9994.9, 'qwub35cd': 9993.9, 'kvh60zd5': 9992.9, 'ziujiigl': 9991.9, '3xw4qjoy': 9990.9}, '32': {'9siu7wgs': 9999.9, 'vxw349ho': 9998.9, 'r7z0nxex': 9997.9, '9it2g2k2': 9996.9, 'h0q93in1': 9995.9, 'jch6vvty': 9994.9, 'tp5q8bbp': 9993.9, 'rpglwjco': 9992.9, '9pdakwmb': 9991.9, '6ru6jwa3': 9990.9}, '33': {'p36zubnf': 9999.9, 'ievuxa6k': 9998.9, 'y2bylnte': 9997.9, 'o8bkorjn': 9996.9, 'natp8lbj': 9995.9, 'khfiy0m2': 9994.9, 'wrgyeng3': 9993.9, 'y883anmp': 9992.9, 'f5xs0tv2': 9991.9, 'zwf26o63': 9990.9}, '34': {'gd5btv69': 9999.9, 'rd6cqdsf': 9998.9, 'tsd6sjcx': 9997.9, 'vjdwh19x': 9996.9, 'rhoo2k3r': 9995.9, 'bi7hy7pk': 9994.9, 'c87a4sf8': 9993.9, 'vcf44w1k': 9992.9, 'eanwxkvt': 9991.9, 'e8ohc25w': 9990.9}, '35': {'fu373osb': 9999.9, 'z0bkpmpk': 9998.9, 'e2zz90sp': 9997.9, 'iukudcbo': 9996.9, 'onipxf2z': 9995.9, 'zxvim4t8': 9994.9, 'vaeyoxv7': 9993.9, 'oll9usqd': 9992.9, 'lqhainz3': 9991.9, '9kb1tt5d': 9990.9}, '36': {'srgi9jc6': 9999.9, '908d8bax': 9998.9, '34ljq0qt': 9997.9, 'm0w0fl2u': 9996.9, 'q5332l0s': 9995.9, '4nfxdppt': 9994.9, '19h2i631': 9993.9, 'yfn9vaan': 9992.9, 'f5g2r4n9': 9991.9, 'ssffvlrl': 9990.9}, '37': {'agox0lbq': 9999.9, 'oi2cm546': 9998.9, '8vl0okiv': 9997.9, 'fofy6whl': 9996.9, 'h8abjsxr': 9995.9, '3sxlvoxf': 9994.9, 'm3505b5w': 9993.9, 'x9az3twa': 9992.9, '7u97in7o': 9991.9, 'k2juhyex': 9990.9}, '38': {'xm0n9iu4': 9999.9, 'pjjrgn05': 9998.9, 'uxehz43v': 9997.9, 'z2n51cet': 9996.9, 'cn3bpmwj': 9995.9, 'n21y5kps': 9994.9, 'iaatjew2': 9993.9, '911ozh90': 9992.9, 'fqlv35vo': 9991.9, '2w5ws14b': 9990.9}, '39': {'zukc3lvq': 9999.9, 'urr5iuy2': 9998.9, '6io0zd0z': 9997.9, 'y26r9g3m': 9996.9, 'iaatjew2': 9995.9, 'fqlv35vo': 9994.9, 'me4tdzvl': 9993.9, '68spkk3y': 9992.9, '3d04p4xp': 9991.9, 'iffgnr51': 9990.9}, '40': {'ypwo98k7': 9999.9, '86byq11c': 9998.9, 'pfhfmck1': 9997.9, 'y5th0mrf': 9996.9, 'j8sg5n5g': 9995.9, 'ttte21up': 9994.9, 'shn7vx3d': 9993.9, 'gfwqog3x': 9992.9, 'a51vkiei': 9991.9, '0xruezf2': 9990.9}, '41': {'80w0wu9e': 9999.9, 'bgpep5lc': 9998.9, '8yvu9xhw': 9997.9, 'fsid4a39': 9996.9, 'wwucpqin': 9995.9, 'orz4be90': 9994.9, 'miayce9l': 9993.9, 'csujgaae': 9992.9, '1lw5vbu9': 9991.9, '753klfdp': 9990.9}, '42': {'8ceblnkz': 9999.9, 'uz34fjyp': 9998.9, 'pt1i1au3': 9997.9, 'bpfwcssk': 9996.9, 'svc2xeh1': 9995.9, 's7pwtw9j': 9994.9, 'fe7e60dl': 9993.9, 'iqe6sdq2': 9992.9, '9vsi8hfx': 9991.9, 'npk92gra': 9990.9}, '43': {'ssv1arr1': 9999.9, '7eksp1sj': 9998.9, 'ekajojon': 9997.9, 'urlsn7vv': 9996.9, 'lcmkribq': 9995.9, 'tkqufxv8': 9994.9, 'gjdza9bh': 9993.9, 'kzpbjvy5': 9992.9, '8ywevius': 9991.9, 'daxggfj5': 9990.9}, '44': {'ugkxxaeb': 9999.9, 'f9syysdw': 9998.9, 'sjenehbl': 9997.9, 'zfea3qg7': 9996.9, 'xfjexm5b': 9995.9, '7qj00qi9': 9994.9, 'qi1henyy': 9993.9, '8je46886': 9992.9, '28utunid': 9991.9, '3ttcfhm3': 9990.9}, '45': {'ilk9u1a8': 9999.9, '0n5n7p4b': 9998.9, '5cmcri6u': 9997.9, 'wbwd7m5w': 9996.9, 'ingq7m2m': 9995.9, 'hze88sr4': 9994.9, '50palac7': 9993.9, 'f6c7e0e4': 9992.9, 'flgtmdfb': 9991.9, 'tj3lmjx3': 9990.9}, '46': {'gd6dd4qm': 9999.9, '6q0y3ewu': 9998.9, 'b8p4l0yp': 9997.9, 'br3ahtf7': 9996.9, 'ocguwlam': 9995.9, 'fqh77aaa': 9994.9, 'ztd7awzv': 9993.9, 'zi86r481': 9992.9, 'hswuwtod': 9991.9, 'dgy7qbl5': 9990.9}, '47': {'u7arfoym': 9999.9, '15zj660u': 9998.9, 'jsjxdmi2': 9997.9, 'sexx9196': 9996.9, 'n0r2imd4': 9995.9, 'njg0ln33': 9994.9, 'el6cvwtk': 9993.9, 'cyn4ssih': 9992.9, '3dcctl1c': 9991.9, 'hlhhvmtu': 9990.9}, '48': {'5eg7hf6r': 9999.9, '22y5ewq6': 9998.9, 'r2x3awlw': 9997.9, 'y2zcwcic': 9996.9, 'wsn7y3wr': 9995.9, 'x6x6a35w': 9994.9, '6gn2seix': 9993.9, 'xu7bazzw': 9992.9, 'xv3k0irk': 9991.9, 'q5efqr7r': 9990.9}, '49': {'nj1p4ehx': 9999.9, 'qg01p4bq': 9998.9, 'dptgg05n': 9997.9, '88px7oq2': 9996.9, '5czqzmvj': 9995.9, 'aed6psww': 9994.9, 'anaqgzvi': 9993.9, '38mhmxvd': 9992.9, 'wdfzrzkt': 9991.9, 'kqanoog7': 9990.9}, '50': {'xbze5s3c': 9999.9, 'aju2nr9x': 9998.9, 'eq2ahtlc': 9997.9, 'hotn7qha': 9996.9, 'tdvb0fhv': 9995.9, 'l9l6z1o0': 9994.9, '1v0f2dtx': 9993.9, 'cyopezdr': 9992.9, 'gysf0vbv': 9991.9, 'q77da2y3': 9990.9}}\n"
          ]
        }
      ],
      "source": [
        "print(bm25_responses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2acaca72-2338-42ea-9a19-f37646245166",
      "metadata": {
        "id": "2acaca72-2338-42ea-9a19-f37646245166"
      },
      "source": [
        "And finally, let's compute the performance of BM25 on this dataset. We are using `nDCG@10` as our metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "cb183c94-7974-4bd8-9ed2-f1426d567592",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb183c94-7974-4bd8-9ed2-f1426d567592",
        "outputId": "89bf5f4c-5b2d-4a2b-f2c7-c9c4066ba247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ndcg_cut_10: 0.6581803724696047\n"
          ]
        }
      ],
      "source": [
        "# specify evaluator\n",
        "METRICS_TO_EVALUATE = {\"ndcg_cut_10\"}\n",
        "evaluator = pytrec_eval.RelevanceEvaluator(qrels, METRICS_TO_EVALUATE)\n",
        "\n",
        "\n",
        "# get score per query\n",
        "eval_per_query = evaluator.evaluate(bm25_responses)\n",
        "\n",
        "\n",
        "# aggregate scores across queries\n",
        "eval_scores = defaultdict(list)\n",
        "\n",
        "for _, vals in eval_per_query.items():\n",
        "    for metric, metric_score in vals.items():\n",
        "        eval_scores[metric].append(metric_score)\n",
        "\n",
        "for metric, _scores in eval_scores.items():\n",
        "    print(f\"{metric}: {np.mean(_scores)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f50faf-9192-43b6-be35-6700b740881d",
      "metadata": {
        "id": "a5f50faf-9192-43b6-be35-6700b740881d"
      },
      "source": [
        "## Bonus section\n",
        "\n",
        "### *Judge* rate\n",
        "Let's do some extra analysis and try to answer the question `\"How many times is an evaluator presented with (query, document) pairs for which there is no ground truth information?\"`\n",
        "In other words, we calculate the percentage of cases where the `qrels` file contains a relevance score for a particular document in the result list.\n",
        "Let's start with BM25 by focusing on the **top-10** retrieved documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5fac2ad-3780-4931-9ed2-127a804fb9f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5fac2ad-3780-4931-9ed2-127a804fb9f3",
        "outputId": "baebad1f-e2e7-4d88-a832-b553fcb88cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Judge rate\" for trec-covid is 92.4%\n"
          ]
        }
      ],
      "source": [
        "TOP_K = 10\n",
        "\n",
        "judge_rate_per_query = []\n",
        "\n",
        "for qid, doc_scores in bm25_responses.items():\n",
        "    top_k_doc_ids = [\n",
        "        doc_id\n",
        "        for doc_id, score in sorted(\n",
        "            doc_scores.items(), key=lambda x: x[1], reverse=True\n",
        "        )[:TOP_K]\n",
        "    ]\n",
        "    if len(top_k_doc_ids) == 0:\n",
        "        continue\n",
        "\n",
        "    nr_labeled_docs = sum(1 for doc_id in top_k_doc_ids if doc_id in qrels[qid])\n",
        "    judge_rate_per_query.append(nr_labeled_docs / len(top_k_doc_ids))\n",
        "\n",
        "print(f'\"Judge rate\" for {DATASET} is {np.mean(judge_rate_per_query) * 100.0:.3}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b35f1415-46dc-4f8e-b4ce-1c575951b7a9",
      "metadata": {
        "id": "b35f1415-46dc-4f8e-b4ce-1c575951b7a9"
      },
      "source": [
        "while for the reranked documents it is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cefae0b2-c963-4d38-b352-94428be35bf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "cefae0b2-c963-4d38-b352-94428be35bf1",
        "outputId": "8c7b500c-cb94-48a0-ce4e-125714521fb4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'results_after_reranking' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-f065148fc98b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjudge_rate_per_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_scores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_after_reranking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     top_k_doc_ids = [\n\u001b[1;32m      5\u001b[0m         \u001b[0mdoc_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results_after_reranking' is not defined"
          ]
        }
      ],
      "source": [
        "judge_rate_per_query = []\n",
        "\n",
        "for qid, doc_scores in results_after_reranking.items():\n",
        "    top_k_doc_ids = [\n",
        "        doc_id\n",
        "        for doc_id, score in sorted(\n",
        "            doc_scores.items(), key=lambda x: x[1], reverse=True\n",
        "        )[:TOP_K]\n",
        "    ]\n",
        "    if len(top_k_doc_ids) == 0:\n",
        "        continue\n",
        "\n",
        "    nr_labeled_docs = sum(1 for doc_id in top_k_doc_ids if doc_id in qrels[qid])\n",
        "    judge_rate_per_query.append(nr_labeled_docs / len(top_k_doc_ids))\n",
        "\n",
        "print(\n",
        "    f'\"Judge rate\" for {DATASET} (reranked) is {np.mean(judge_rate_per_query) * 100.0:.3}%'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eae7142374e2f7a",
      "metadata": {
        "id": "1eae7142374e2f7a"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "392ab084d5bc024",
      "metadata": {
        "id": "392ab084d5bc024"
      },
      "source": [
        "### Confidence intervals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fb391b00a7efd58",
      "metadata": {
        "id": "6fb391b00a7efd58"
      },
      "source": [
        "In this section we will briefly touch upon the concepts of `confidence intervals` and `statistical significance` and we will see how we can use them to determine whether improvements in our pipelines are significant or not.\n",
        "\n",
        "We can think of it as follows: Our goal is to estimate the performance of our pipeline (retrieval and/or reranking) on a target corpus. Ideally, we would like to have access to **all** queries that our end-users will run against it but of course this is impossible. Instead, we have the set of test queries provided by the benchmark and we implicitly assume that the performance on this set can act as an accurate proxy of the overall performance (in the ideal scenario).\n",
        "\n",
        "But we can make some extra assumptions to increase the reliability of our analysis. [Confidence intervals](https://en.wikipedia.org/wiki/Confidence_interval), a concept from statistical theory, give us a tool to handle our uncertainty. By setting a certain level of confidence, let's go with 95% in this example, we can derive a range of values that will likely contain the parameter of interest (here the performance in the **ideal** scenario). In other words, if we repeated the same process an infinite number of times (by drawing different test sets) we could be confident that in 95% of them the confidence interval would encompass the true value.\n",
        "\n",
        "The code below shows an example of deriving confidence intervals using [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_\\(statistics\\)) combined with the `percentile` method. It should be noted that this statistic is affected a lot by the number and the variability of queries in the dataset i.e. smaller confidence intervals are expected for larger query sets and vice versa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b5563e681b4236",
      "metadata": {
        "id": "3b5563e681b4236"
      },
      "outputs": [],
      "source": [
        "def get_ci_with_bootstrapping(scores: list, nr_bootstraps=1000, percentile=95):\n",
        "    \"\"\"\n",
        "    Compute confidence intervals using bootstrapping and the percentile method\n",
        "    Args:\n",
        "        `scores`: The list of scores to be averaged\n",
        "        `nr_bootstraps`: The number of bootstrap samples to collect\n",
        "        `percentile`: The type of confidence interval to compute. It should be a number in (0, 100),\n",
        "            by default it computes 95% CI\n",
        "    Returns:\n",
        "        The confidence interval\n",
        "    \"\"\"\n",
        "    estimates = []\n",
        "    for _ in range(nr_bootstraps):\n",
        "        sample = np.random.choice(scores, len(scores), replace=True)\n",
        "        estimates.append(np.mean(sample))\n",
        "\n",
        "    half_percentile = (100.0 - percentile) / 2.0\n",
        "    return np.percentile(estimates, [half_percentile, 100.0 - half_percentile])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "701ed82491660fd6",
      "metadata": {
        "id": "701ed82491660fd6"
      },
      "source": [
        "and we can apply it to our results as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f2f080185190b58",
      "metadata": {
        "id": "9f2f080185190b58"
      },
      "outputs": [],
      "source": [
        "ndcg_scores = post_reranking_eval_scores[\"ndcg_cut_10\"]\n",
        "get_ci_with_bootstrapping(ndcg_scores, percentile=95, nr_bootstraps=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4d62dfde0c588b",
      "metadata": {
        "id": "be4d62dfde0c588b"
      },
      "source": [
        "The way to interpret this would be to say that we are 95% confident that the `nDCG@10` score in the ideal scenario lies within that interval\n",
        "\n",
        "Confidence intervals can be used in the context of significance testing. For example, if we wanted to compare two pipelines (retrieval and/or reranking) on a dataset one way to do this would be to:\n",
        "* Decide on a confidence level (e.g. 90% or 95%)\n",
        "* Compute confidence intervals for the performance of model A\n",
        "* Compute confidence intervals for the performance of model B\n",
        "* Check whether there is an overlap between the two intervals.\n",
        "\n",
        "In the last step, if there is **no** overlap we can say that the observed difference in performance between the two pipelines is **statistically significant**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f8bf706821ab252",
      "metadata": {
        "id": "4f8bf706821ab252"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "a5f50faf-9192-43b6-be35-6700b740881d"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0056b9b61a2b4ddbb5cc935bb6d00b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00a1245d83ef46ed8a301e062d8fd2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "059c115f2973406f97d3376a00aea6fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f2e2b775d24d6db28b88111489bd22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac3cf6d2df14fdea601dd7d03953406": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b6d8b34cf764aaaad382821aa8093ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "119b586f69bc4b8dbcbcbd49163283a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d0dbd3ac0346aa882eb5fa08dce1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8af4b259809d4c4bb8152aac7053725f",
            "placeholder": "​",
            "style": "IPY_MODEL_9f976bc08ca041d791527595cef23527",
            "value": " 50/50 [00:00&lt;00:00, 1424.90 examples/s]"
          }
        },
        "2f777fa71ccc4e74933f3949182355f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f8aa6470d854dbcbf94a96af4dfdffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4883a18a6a463da8b6b762a8c33d98",
            "placeholder": "​",
            "style": "IPY_MODEL_67e5eb9cc9c64d1ca8d9ee3d420b5608",
            "value": " 3.83M/3.83M [00:01&lt;00:00, 3.09MB/s]"
          }
        },
        "2fb9821124624e0f8f6743489d668021": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aba514d1e384a1a98abd9e0babb5fbb",
              "IPY_MODEL_a15fd83f19b9483394151519d0e540d3",
              "IPY_MODEL_69adb50083564854a5be5d8f80dfc44e"
            ],
            "layout": "IPY_MODEL_f35e0db79c4c438cb8017f960715b3c5"
          }
        },
        "2ff0a8eee73d437b9f4ca18c3aa70f97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3593407a12a7481b8c6230a9e050668f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38bc5077a0e14303ba16a25ab7fb210e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d394f3f887b4ae3a27085f534d690ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a98cad90972e407cb0b364911948afd6",
            "max": 3833253,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00a1245d83ef46ed8a301e062d8fd2a1",
            "value": 3833253
          }
        },
        "42834e1e98f741b4873eff59b6bd6163": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821c1f240a6849839c816e84056eb569",
            "placeholder": "​",
            "style": "IPY_MODEL_52a01e6aaed04e4396d62d9135a3eb2e",
            "value": " 4.75k/4.75k [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "42b58704cb744488b0e4c27792150bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aba514d1e384a1a98abd9e0babb5fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_059c115f2973406f97d3376a00aea6fe",
            "placeholder": "​",
            "style": "IPY_MODEL_5ff518c12e1a4e00a83ebfbbf2bb3269",
            "value": "Filter: 100%"
          }
        },
        "52646ef672254fed9414d2e799c66942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52a01e6aaed04e4396d62d9135a3eb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a88286f9354fea87cbf4e7c86430de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4729e6ad8d54a4c9b853da46ac6eb06",
              "IPY_MODEL_3d394f3f887b4ae3a27085f534d690ab",
              "IPY_MODEL_2f8aa6470d854dbcbf94a96af4dfdffa"
            ],
            "layout": "IPY_MODEL_0056b9b61a2b4ddbb5cc935bb6d00b7e"
          }
        },
        "5757d3cd5f684f3e888b7353ff272a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57affd030eb84a4fbc2910328b948ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ff0a8eee73d437b9f4ca18c3aa70f97",
            "max": 4753,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52646ef672254fed9414d2e799c66942",
            "value": 4753
          }
        },
        "58cbc6b8ae2e432aafdbf1ba3894a67e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e09bea8ec6348a39a37cd2ccc9d393e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebb8366fd7904c85a90a388ea8ddb4aa",
            "placeholder": "​",
            "style": "IPY_MODEL_3593407a12a7481b8c6230a9e050668f",
            "value": "Downloading data: 100%"
          }
        },
        "5ff518c12e1a4e00a83ebfbbf2bb3269": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67e5eb9cc9c64d1ca8d9ee3d420b5608": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "690cf81630c143f597c85a353c7ffdb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69adb50083564854a5be5d8f80dfc44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f71b21a94a44928aa82fa4d194b50ce",
            "placeholder": "​",
            "style": "IPY_MODEL_38bc5077a0e14303ba16a25ab7fb210e",
            "value": " 50/50 [00:00&lt;00:00, 1140.04 examples/s]"
          }
        },
        "6aea695ca483431295c286f9eb9c6fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4883a18a6a463da8b6b762a8c33d98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821c1f240a6849839c816e84056eb569": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88fc531e854b46c5882a738e44aba762": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ac3cf6d2df14fdea601dd7d03953406",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8dc67632ee84ca9aa6eccb50c7aadcf",
            "value": 50
          }
        },
        "8a8fdbe5e50a468d8d1200b60c8aada2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e05d3c875d864dc5a812794ea7c5256e",
              "IPY_MODEL_8c47c80da01c4261b686f7326f11b990",
              "IPY_MODEL_fe7b6b97dd1b41dc9f9ac95d920b53b0"
            ],
            "layout": "IPY_MODEL_06f2e2b775d24d6db28b88111489bd22"
          }
        },
        "8af4b259809d4c4bb8152aac7053725f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c47c80da01c4261b686f7326f11b990": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_690cf81630c143f597c85a353c7ffdb7",
            "max": 66336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d69c7e3008094032bc2a3e89a77866f9",
            "value": 66336
          }
        },
        "9292bb4ff64c4435a060f9202250c26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e09bea8ec6348a39a37cd2ccc9d393e",
              "IPY_MODEL_57affd030eb84a4fbc2910328b948ba4",
              "IPY_MODEL_42834e1e98f741b4873eff59b6bd6163"
            ],
            "layout": "IPY_MODEL_d8b60cc1d160439a8036604a2286b927"
          }
        },
        "9f71b21a94a44928aa82fa4d194b50ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f976bc08ca041d791527595cef23527": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a15fd83f19b9483394151519d0e540d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_119b586f69bc4b8dbcbcbd49163283a9",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5757d3cd5f684f3e888b7353ff272a3c",
            "value": 50
          }
        },
        "a98cad90972e407cb0b364911948afd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab4ae86ce2d24e9d8bd89332bd25eb57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58cbc6b8ae2e432aafdbf1ba3894a67e",
            "placeholder": "​",
            "style": "IPY_MODEL_f88bd71942934410ad7e9265967298ee",
            "value": "Generating queries split: 100%"
          }
        },
        "b4729e6ad8d54a4c9b853da46ac6eb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42b58704cb744488b0e4c27792150bfb",
            "placeholder": "​",
            "style": "IPY_MODEL_2f777fa71ccc4e74933f3949182355f5",
            "value": "Downloading data: 100%"
          }
        },
        "b8dc67632ee84ca9aa6eccb50c7aadcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc81f4bf513f4cb2b07270f1669f53dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c495710ac7194c599cbe4f02f025e3cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69c7e3008094032bc2a3e89a77866f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8b60cc1d160439a8036604a2286b927": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05d3c875d864dc5a812794ea7c5256e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc81f4bf513f4cb2b07270f1669f53dc",
            "placeholder": "​",
            "style": "IPY_MODEL_0b6d8b34cf764aaaad382821aa8093ef",
            "value": "Generating test split: 100%"
          }
        },
        "e70f9877b9864ebaa3491b2ecf3c0185": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebb8366fd7904c85a90a388ea8ddb4aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35e0db79c4c438cb8017f960715b3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a83ce3f6334d669c5f2092cf20bb53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab4ae86ce2d24e9d8bd89332bd25eb57",
              "IPY_MODEL_88fc531e854b46c5882a738e44aba762",
              "IPY_MODEL_12d0dbd3ac0346aa882eb5fa08dce1da"
            ],
            "layout": "IPY_MODEL_c495710ac7194c599cbe4f02f025e3cd"
          }
        },
        "f88bd71942934410ad7e9265967298ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe7b6b97dd1b41dc9f9ac95d920b53b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e70f9877b9864ebaa3491b2ecf3c0185",
            "placeholder": "​",
            "style": "IPY_MODEL_6aea695ca483431295c286f9eb9c6fa3",
            "value": " 66336/66336 [00:00&lt;00:00, 611951.08 examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
